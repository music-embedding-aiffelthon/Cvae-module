{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0caeaacb-0e01-4f4a-9b76-b298fe810160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022-09-02 16:23 Seoul\n",
    "\n",
    "# --- import dataset ---\n",
    "from utils.dataloader import mel_dataset\n",
    "from utils.losses import *\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "# --- import model ---\n",
    "# from model.Conv1d_model import Encoder as Encoder1d\n",
    "\n",
    "from model.Conv2d_model import Conv2d_VAE, Encoder\n",
    "\n",
    "# --- import framework ---\n",
    "import flax \n",
    "import flax.linen as nn\n",
    "from flax.training import train_state\n",
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "import cloudpickle\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00ec061d-32f3-499d-b3f7-06e7ad4fb3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "lr = 0.0001\n",
    "dilation = True\n",
    "key = jax.random.PRNGKey(303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ce4d9-dcd4-44c1-9f76-1bf5194c5d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv2d_VAE(dilation=dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e38d19d-0f82-4c95-9657-8e867ab17335",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.ones((16, 48, 1876))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f173f159-633f-45e3-8332-41864dd9da19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = model.init({'params': key}, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c941997-3a06-499a-b80a-dcda8d3050e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =  os.path.join(os.path.expanduser('~'),'dev_dataset') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f924a86-3ecc-4abc-9e82-523c8d95a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68886139-48fb-442d-ba79-6ec74afef172",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mel_dataset(data_dir, 'total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a422e2f4-8ef0-4266-a7ce-071de795a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(data)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "test_size = dataset_size - train_size\n",
    "    \n",
    "train_dataset, test_dataset = random_split(data, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce17ef-d4bc-4951-a0af-044fbc3f560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- collate batch for dataloader ---\n",
    "def collate_batch(batch):\n",
    "    x_train = [x for x, _ in batch]\n",
    "    y_train = [y for _, y in batch]                  \n",
    "\n",
    "    return np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebe4c31-33cd-44b9-a981-88376a12a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=int(32/4), shuffle=True, num_workers=0, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b2c0b-46f1-499a-a127-5717bac0d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_state(model, x_shape, key, lr) -> train_state.TrainState:\n",
    "    params = model.init({'params': key}, jnp.ones(x_shape))\n",
    "    optimizer = optax.adam(learning_rate=lr)\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        tx=optimizer,\n",
    "        params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e79d22-5ab8-4b99-8264-89e0c507c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.init({'params': key}, jnp.ones((16,48,1876)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c573b50-650a-49db-b370-28b17c971990",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = init_state(model, \n",
    "                   next(iter(train_dataloader))[0].shape, \n",
    "                   key, \n",
    "                   lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be2879-848d-47d5-9497-7ce1d062237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_state = state.params['params']['encoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b27d6-1d6a-45a7-b77a-f8851a85de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_stats = state.params['batch_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc84363-00d4-4f22-a2db-fe315f187270",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_batch = state.params['batch_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8db5ad-3ad9-4322-9811-58c8ca9197f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9011e79-e6a7-4e53-a620-df75a8dbcd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent= encoder.apply({'params':enc_state, 'batch_stats':enc_batch}, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f854f03d-9d96-4c56-bf35-e56deb0e43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_dataloader))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e9adad-5263-49f4-8b5b-fc39238cf121",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = jnp.array(1, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2478e6-9d23-44b3-9f91-d3876ec57f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embed(num_embeddings=10, features=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e241451-19f1-4ac9-8d3f-fb1f5f39d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85287d5-2a8c-4fbb-b506-277eef2c5a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vari = emb.init(key, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdadaae-905d-4e29-8986-9bb9accbabf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_output =emb.apply(emb_vari,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a31ae-0f7f-466a-978c-73b6d0559ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7493c4-2b17-40ba-b12d-5de6f99ebd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.ones((16,48,1876))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead4c25-25c9-45e0-b347-7e36af6d2cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.expand_dims(x, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe8b85e-492c-4ac4-ba01-48d922090b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2498ab-38f2-4097-ae15-421d2a3ca56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv(512, kernel_size=(3,3),  strides=[2,2], padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e74e2ff-f6be-4bbb-8c32-4a00f2592716",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_vari = conv.init(key, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab85836-aa47-4114-bf54-e887b9a81e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.apply(init_vari, x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160b5023-7a1a-4a23-adad-053410cafe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.ones((16, 24, 938, 512))\n",
    "y = jnp.ones((16, 1,1, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa5fff4-d953-441b-bbb7-9ba38e9c2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = x+y\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d700df-51da-42e6-9f16-1a775702fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.ones((16, 1, 512))\n",
    "x = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83812694-2466-4299-8922-fe43113cb5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    \n",
    "    def setup(self):\n",
    "        self.embed = nn.Embed(num_embeddings=10, features=512)\n",
    "        \n",
    "    def __call__(self, y):\n",
    "        emb = self.embed(features=512)\n",
    "        emb_vari = emb.init(key, y)\n",
    "        y =emb.apply(emb_vari,y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9c05bf1-1cc3-4283-be83-986c80b6b04e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "from flax import linen as nn\n",
    "from typing import Callable, Any, Optional\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    linear:bool=False\n",
    "    dilation:bool=False\n",
    "    latent_size:int=512\n",
    "    hidden_layer:int=512\n",
    "    n_features:int=30\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x,y):\n",
    "        \n",
    "        x = jnp.expand_dims(x, axis=-1)\n",
    "        y = nn.Embed(num_embeddings=10, features=512)(y)\n",
    "        \n",
    "        y = jnp.expand_dims(y, axis=1)\n",
    "        \n",
    "        y = jnp.expand_dims(y, axis=1)\n",
    "        \n",
    "        # x = x + y \n",
    "        print(x.shape)\n",
    "        print(y.shape)\n",
    "\n",
    "        \n",
    "        # 0 \n",
    "        if self.dilation:\n",
    "            x = nn.Conv(512, kernel_size=(3,3),  strides=[2,2], kernel_dilation=1, padding='same')(x)\n",
    "            x = x + y \n",
    "        else:\n",
    "            x = nn.Conv(512, kernel_size=(3,3),  strides=[2,2], padding='same')(x)\n",
    "            x = x + y\n",
    "            print(x.shape)\n",
    "            print(y.shape)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "\n",
    "        # 1\n",
    "        if self.dilation:\n",
    "            x = nn.Conv(512,kernel_size=(3,3), kernel_dilation=1, padding='same')(x)\n",
    "        else:\n",
    "            x = nn.Conv(512,kernel_size=(3,3),  padding='same')(x)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "        x = nn.max_pool(x, window_shape=(2,2), strides=(2,2))\n",
    "\n",
    "        # 2 \n",
    "        if self.dilation:\n",
    "            x = nn.Conv(256,kernel_size=(3,3), kernel_dilation=2, padding='same')(x)\n",
    "        else:            \n",
    "            x = nn.Conv(256,kernel_size=(3,3),  padding='same')(x)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    " \n",
    "        # 3\n",
    "        if self.dilation:\n",
    "            x = nn.Conv(128,kernel_size=(3,3), kernel_dilation=2, padding='same')(x)\n",
    "        else:\n",
    "            x = nn.Conv(128,kernel_size=(3,3), padding='same')(x)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "        \n",
    "        # 4\n",
    "        if self.dilation:\n",
    "            x = nn.Conv(64, kernel_size=(3,3), kernel_dilation=4, padding='same')(x)\n",
    "        else:\n",
    "            x = nn.Conv(64,kernel_size=(3,3), padding='same')(x)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "        \n",
    "        # 5\n",
    "        if self.dilation:\n",
    "            x = nn.Conv(32, kernel_size=(3,3), kernel_dilation=4, padding='same')(x)\n",
    "        else:\n",
    "            x = nn.Conv(32, kernel_size=(3,3),  padding='same')(x)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "        \n",
    "        # 6\n",
    "        if self.dilation:\n",
    "            x = nn.Conv(16, kernel_size=(3,3), kernel_dilation=4, padding='same')(x)\n",
    "        else:\n",
    "            x = nn.Conv(16, kernel_size=(3,3), padding='same')(x)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "        \n",
    "        # 7\n",
    "        if self.dilation:\n",
    "            x = nn.Conv(1,kernel_size=(3,3), strides=[1,1], kernel_dilation=4, padding='same')(x)\n",
    "        else:\n",
    "            x = nn.Conv(1,kernel_size=(3,3), strides=[1,1],  padding='same')(x)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "\n",
    "        \n",
    "        x = x.reshape(x.shape[0], -1) \n",
    "        \n",
    "        \n",
    "        # mean_x = nn.Dense(512, name='fc3_mean')(x)\n",
    "        # logvar_x = nn.Dense(512, name='fc3_logvar')(x)  # (128, 12, 469, 20)\n",
    "        \n",
    "        # z = reparameterize(z_rng, mean_x, logvar_x)\n",
    "        \n",
    "        z = nn.Dense(features=self.latent_size, name='latent_vector')(x)\n",
    "        \n",
    "        if self.linear:\n",
    "            z = nn.Dense(self.hidden_layer, name='linear_hidden_layer')(z)    \n",
    "            z = jax.nn.leaky_relu(z) # nn.tanh(x)\n",
    "            z = nn.Dense(self.n_features, name='linear_classification')(z)\n",
    "        \n",
    "        \n",
    "        return z \n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    dilation:bool=False\n",
    "    latent_size:int=512\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x,y):\n",
    "        \n",
    "        x = nn.Dense(12 * 469 * 1)(x)\n",
    "        x = x.reshape(x.shape[0], 12, 469, 1)\n",
    "        y = nn.Embed(num_embeddings=10, features=32)(y)\n",
    "        \n",
    "        y = jnp.expand_dims(y, axis=1)\n",
    "        y = jnp.expand_dims(y, axis=1)\n",
    "        print(y.shape)\n",
    "        \n",
    "    \n",
    "        # 0\n",
    "        if self.dilation:\n",
    "            x = nn.ConvTranspose(32, kernel_size=(3,3), strides=[1,1], kernel_dilation=(4,4))(x)\n",
    "            x = x+y\n",
    "            print(x.shape)\n",
    "            print(y.shape)\n",
    "        else:\n",
    "            x = nn.ConvTranspose(32, kernel_size=(3,3), strides=[1,1])(x)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "        \n",
    "        # 1\n",
    "        if self.dilation:\n",
    "            x = nn.ConvTranspose(64, kernel_size=(3,3))(x)\n",
    "        else:\n",
    "            x = nn.ConvTranspose(64, kernel_size=(3,3), strides=[1,1],kernel_dilation=(2,2))(x)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)        \n",
    "        \n",
    "        # 2\n",
    "        if self.dilation:\n",
    "            x = nn.ConvTranspose(128, kernel_size=(3,3), strides=[2,2], kernel_dilation=(2,2))(x)\n",
    "        else:             \n",
    "            x = nn.ConvTranspose(128, kernel_size=(3,3), strides=[2,2])(x)                   \n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        x = nn.normalization.BatchNorm(True)(x)\n",
    "        \n",
    "        \n",
    "        # 3\n",
    "        if self.dilation:\n",
    "            x = nn.ConvTranspose(256, kernel_size=(3,3), strides=[2,2], kernel_dilation=(2,2))(x)\n",
    "        else:\n",
    "            x = nn.ConvTranspose(256, kernel_size=(3,3), strides=[2,2])(x)\n",
    "            \n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        \n",
    "        \n",
    "        x = nn.ConvTranspose(1, kernel_size=(3,3), strides=[1,1])(x)\n",
    "        x = jax.nn.tanh(x)\n",
    "        x = jnp.squeeze(x, axis=-1)\n",
    "        return x\n",
    "        \n",
    "\n",
    "class Conv2d_CAE(nn.Module):\n",
    "    dilation:bool=False\n",
    "    latent_size:int=512\n",
    "    n_features:int=30\n",
    "    \n",
    "    def setup(self):\n",
    "        self.encoder = Encoder(dilation=self.dilation, \n",
    "                               linear=False, \n",
    "                               latent_size=self.latent_size,\n",
    "                               n_features=self.n_features,)\n",
    "        self.decoder = Decoder(dilation=self.dilation, latent_size=self.latent_size)\n",
    "        \n",
    "        \n",
    "    def __call__(self, x,y):\n",
    "        \n",
    "        z = self.encoder(x,y)\n",
    "        recon_x = self.decoder(z,y)\n",
    "        \n",
    "        return recon_x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816ca3f7-1e6c-408b-9152-6076902d2a18",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 48, 1876, 1)\n",
      "(16, 1, 1, 512)\n",
      "(16, 1, 1, 32)\n",
      "(16, 12, 469, 32)\n",
      "(16, 1, 1, 32)\n",
      "(16, 48, 1876, 1)\n",
      "(16, 1, 1, 512)\n",
      "(16, 1, 1, 32)\n",
      "(16, 12, 469, 32)\n",
      "(16, 1, 1, 32)\n",
      "(16, 48, 1876, 1)\n",
      "(16, 1, 1, 512)\n",
      "(16, 24, 938, 512)\n",
      "(16, 1, 1, 512)\n",
      "(16, 1, 1, 32)\n",
      "(16, 48, 1876, 1)\n",
      "(16, 1, 1, 512)\n",
      "(16, 24, 938, 512)\n",
      "(16, 1, 1, 512)\n",
      "(16, 1, 1, 32)\n",
      "test complete!\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    x = jnp.ones((16, 48, 1876))\n",
    "    y = jnp.ones((16))\n",
    "    y = jnp.array(y, dtype='int32')\n",
    "    \n",
    "    z = jnp.ones((16, 20))\n",
    "\n",
    "    key = jax.random.PRNGKey(32)\n",
    "    \n",
    "    params = Conv2d_CAE(dilation=True).init({'params': key},x,y)\n",
    "    result = Conv2d_CAE(dilation=True).apply(params, x,y)\n",
    "\n",
    "    params = Conv2d_CAE(dilation=False).init({'params': key}, x, y)\n",
    "    result = Conv2d_CAE(dilation=False).apply(params, x,y)\n",
    "\n",
    "    print('test complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095a6a46-b2fe-488c-a6cd-6651b5d32be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Conv2d_CAE(dilation=True).init({'params': key},x,y,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a6ebe-0c55-460b-a7d8-4fe2da05c5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
