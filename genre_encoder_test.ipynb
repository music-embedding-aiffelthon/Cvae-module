{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8827325-bfc1-42a8-8790-80ad887cd743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import mel_dataset\n",
    "from utils.losses import *\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# --- import model ---\n",
    "from model.Conv2d_model import Conv2d_VAE\n",
    "\n",
    "# --- import framework ---\n",
    "import flax \n",
    "from flax import jax_utils\n",
    "import flax.linen as nn\n",
    "from flax.training import train_state, common_utils\n",
    "from flax.core.frozen_dict import unfreeze, freeze\n",
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.config_hook import yaml_config_hook\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3369a6ee-e508-40a3-87f9-659f3e23bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/home/anthonypark6904/dev_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967c08a9-8f95-49e2-a648-ac83c97b01c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load song_meta.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 707989/707989 [00:00<00:00, 801195.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load complete!\n",
      "\n",
      "Load file list...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 54.94it/s]\n"
     ]
    }
   ],
   "source": [
    "data = mel_dataset(dataset_dir, 'total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80994143-7faf-4758-960f-28dd6a68c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- collate batch for dataloader ---\n",
    "def collate_batch(batch):\n",
    "    x_train = [x for x, _ in batch]\n",
    "    y_train = [y for _, y in batch]                  \n",
    "        \n",
    "    return np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a94d1c1-14c6-4c55-a84e-e39136e87edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.dataloader.mel_dataset at 0x7faa854c4b20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e39053ce-dd6f-4d48-ac64-f3dbc7593096",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = os.path.join(os.path.expanduser('~'),'trainer_module/config')     \n",
    "config = yaml_config_hook(os.path.join(config_dir, 'config.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "456c6d28-5497-4a2c-ab63-0802f74091a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-11 15:40:26.905194: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "WARNING:absl:GlobalAsyncCheckpointManager is not imported correctly. Checkpointing of GlobalDeviceArrays will not be available.To use the feature, install tensorstore.\n"
     ]
    }
   ],
   "source": [
    "from train_module import TrainerModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1e7e4e1-0d5a-4601-b28c-72a934a10d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: seegong (aiffelthon). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/anthonypark6904/genre_encoder/wandb/run-20220911_154104-1cv3bfjy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/aiffelthon/Conv2d/runs/1cv3bfjy\" target=\"_blank\">decent-grass-121</a></strong> to <a href=\"https://wandb.ai/aiffelthon/Conv2d\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = TrainerModule(seed=125, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8220c715-e6a1-4086-9fcb-4fca0ca6417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(data)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(data, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=0, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=0, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6457b3c9-6e0e-44b3-b8bc-999ec97d84f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|                                           | 0/21 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ScopeParamShapeError",
     "evalue": "Inconsistent shapes between value and initializer for parameter \"kernel\" in \"/encoder/Conv_0\": (8, 3, 3, 1, 512), (3, 3, 1, 512). (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScopeParamShapeError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstep)\n",
      "File \u001b[0;32m~/genre_encoder/train_module.py:125\u001b[0m, in \u001b[0;36mTrainerModule.train_model\u001b[0;34m(self, train_dataloader, test_dataloader, num_epochs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m jax_utils\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m jax_utils\u001b[38;5;241m.\u001b[39munreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate)\n",
      "File \u001b[0;32m~/genre_encoder/train_module.py:137\u001b[0m, in \u001b[0;36mTrainerModule.train_epoch\u001b[0;34m(self, epoch, train_dataloader, test_dataloader)\u001b[0m\n\u001b[1;32m    134\u001b[0m train_batch \u001b[38;5;241m=\u001b[39m common_utils\u001b[38;5;241m.\u001b[39mshard(jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(np\u001b[38;5;241m.\u001b[39masarray, \u001b[38;5;28mnext\u001b[39m(train_dataiter)))\n\u001b[1;32m    135\u001b[0m test_batch \u001b[38;5;241m=\u001b[39m common_utils\u001b[38;5;241m.\u001b[39mshard(jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(np\u001b[38;5;241m.\u001b[39masarray, \u001b[38;5;28mnext\u001b[39m(test_dataiter)))\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m test_loss, recon_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, test_batch)\n\u001b[1;32m    140\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: jax\u001b[38;5;241m.\u001b[39mdevice_get(train_loss\u001b[38;5;241m.\u001b[39mmean()), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: jax\u001b[38;5;241m.\u001b[39mdevice_get(test_loss\u001b[38;5;241m.\u001b[39mmean())})\n",
      "    \u001b[0;31m[... skipping hidden 17 frame]\u001b[0m\n",
      "File \u001b[0;32m~/genre_encoder/train_module.py:68\u001b[0m, in \u001b[0;36mTrainerModule.create_functions.<locals>.train_step\u001b[0;34m(state, batch)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[1;32m     67\u001b[0m grad_fn \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvalue_and_grad(loss_fn)\n\u001b[0;32m---> 68\u001b[0m loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m grads \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mpmean(grads, axis_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     70\u001b[0m state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mapply_gradients(grads\u001b[38;5;241m=\u001b[39mgrads)  \u001b[38;5;66;03m# Optimizer update step\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m~/genre_encoder/train_module.py:63\u001b[0m, in \u001b[0;36mTrainerModule.create_functions.<locals>.train_step.<locals>.loss_fn\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     61\u001b[0m mel, _ \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     62\u001b[0m mel \u001b[38;5;241m=\u001b[39m (mel\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m200\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m---> 63\u001b[0m recon_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m loss \u001b[38;5;241m=\u001b[39m ((recon_x \u001b[38;5;241m-\u001b[39m mel) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "File \u001b[0;32m~/genre_encoder/model/Conv2d_model.py:181\u001b[0m, in \u001b[0;36mConv2d_VAE.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 181\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     recon_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z)\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m recon_x\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/genre_encoder/model/Conv2d_model.py:29\u001b[0m, in \u001b[0;36mEncoder.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 0 \u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation:\n\u001b[0;32m---> 29\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_dilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv(\u001b[38;5;241m512\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m),  strides\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/flax/linen/linear.py:415\u001b[0m, in \u001b[0;36m_Conv.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m kernel_shape:\n\u001b[1;32m    412\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMask needs to have the same shape as weights. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    413\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShapes are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 415\u001b[0m kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkernel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m   kernel \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/flax/core/scope.py:768\u001b[0m, in \u001b[0;36mScope.param\u001b[0;34m(self, name, init_fn, *init_args)\u001b[0m\n\u001b[1;32m    763\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m val, abs_val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(value_flat, abs_value_flat):\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;66;03m# NOTE: We could check dtype consistency here as well but it's\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;66;03m# usefuleness is less obvious. We might intentionally change the dtype\u001b[39;00m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# for inference to a half float type for example.\u001b[39;00m\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mshape(val) \u001b[38;5;241m!=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mshape(abs_val):\n\u001b[0;32m--> 768\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mScopeParamShapeError(name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_text,\n\u001b[1;32m    769\u001b[0m                                         jnp\u001b[38;5;241m.\u001b[39mshape(val), jnp\u001b[38;5;241m.\u001b[39mshape(abs_val))\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    771\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_mutable_collection(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mScopeParamShapeError\u001b[0m: Inconsistent shapes between value and initializer for parameter \"kernel\" in \"/encoder/Conv_0\": (8, 3, 3, 1, 512), (3, 3, 1, 512). (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)"
     ]
    }
   ],
   "source": [
    "trainer.train_model(train_dataloader, test_dataloader)\n",
    "trainer.save_model(trainer.state.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c669982a-8d7d-4d66-8f23-13a8bd93cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = jnp.ones((32,48,1876))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "770e22a4-c2f1-4428-88c6-3c818a171aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 48, 1876)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7f04b33-0e39-46ba-b6fa-78d45e60678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2f96c80-8d8d-43fc-8258-fcd92939cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.expand_dims(a, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c19454ff-2d96-49d8-b228-df2fe4ba3a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 48, 1876, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86a168d1-3f8d-4909-ba0e-febd24b67101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "jax.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d38c69c-4ef8-44ab-a6bb-e29c49f51fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022-09-02 16:23 Seoul\n",
    "\n",
    "# --- import dataset ---\n",
    "from utils.losses import *\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# --- import model ---\n",
    "from model.Conv2d_model import Conv2d_VAE, Encoder\n",
    "\n",
    "# --- import framework ---\n",
    "import flax \n",
    "from flax import jax_utils\n",
    "from flax.training import train_state, common_utils, checkpoints\n",
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import wandb\n",
    "from utils.config_hook import yaml_config_hook\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "# --- Define config ---\n",
    "\n",
    "config_dir = os.path.join(os.path.expanduser('~'),'module/config')     \n",
    "config = yaml_config_hook(os.path.join(config_dir, 'config.yaml'))\n",
    "\n",
    "class TrainerModule:\n",
    "\n",
    "    def __init__(self, \n",
    "                 seed,\n",
    "                 config):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.seed = seed\n",
    "        self.exmp = jnp.ones((self.config['batch_size'], 48, 1876))\n",
    "        # Create empty model. Note: no parameters yet\n",
    "        self.model = Conv2d_VAE(dilation=self.config['dilation'], latent_size=self.config['latent_size'])\n",
    "        # self.linear_model = linear_evaluation()\n",
    "        self.Encoder = Encoder(dilation=self.config['dilation'])\n",
    "        # Prepare logging\n",
    "        self.log_dir = self.config['checkpoints_path']\n",
    "        # Create jitted training and eval functions\n",
    "        self.create_functions()\n",
    "        # Initialize model\n",
    "        self.init_model()\n",
    "        wandb.init(\n",
    "        project=config['model_type'],\n",
    "        entity='aiffelthon',\n",
    "        config=config\n",
    "        )\n",
    "        \n",
    "    def create_functions(self):\n",
    "        # Training function\n",
    "        def train_step(state, batch):\n",
    "            \n",
    "            def loss_fn(params):\n",
    "                mel, _ = batch\n",
    "                mel = (mel/200) + 0.5\n",
    "                recon_x = self.model.apply(params, mel)\n",
    "                loss = ((recon_x - mel) ** 2).mean()\n",
    "                return loss\n",
    "            \n",
    "            grad_fn = jax.value_and_grad(loss_fn)\n",
    "            loss, grads = grad_fn(state.params)\n",
    "            grads = jax.lax.pmean(grads, axis_name='batch')\n",
    "            state = state.apply_gradients(grads=grads)  # Optimizer update step\n",
    "            \n",
    "            return state, loss\n",
    "        self.train_step = jax.pmap(partial(train_step), axis_name='batch')\n",
    "        \n",
    "        # Eval function        \n",
    "        def eval_step(state, batch):\n",
    "            mel, _ = batch\n",
    "            mel = (mel/200) + 0.5\n",
    "            recon_x = self.model.apply(state.params, mel)\n",
    "            loss = ((recon_x - mel) ** 2).mean()\n",
    "            \n",
    "            return loss, recon_x        \n",
    "        self.eval_step = jax.pmap(partial(eval_step), axis_name='batch')\n",
    "        \n",
    "        \n",
    "    def create_png(test_x, recon):\n",
    "        recon = jax_utils.unreplicate(recon)\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        im1 = ax1.imshow(recon_x[0], aspect='auto', origin='lower', interpolation='none')\n",
    "        fig1.colorbar(im1)\n",
    "        fig1.savefig('recon.png')\n",
    "        plt.close(fig1)\n",
    "\n",
    "        fig2, ax2 = plt.subplots()\n",
    "        im2 = ax2.imshow(test_x[0], aspect='auto', origin='lower', interpolation='none')\n",
    "        fig2.colorbar(im2)\n",
    "        fig2.savefig('x.png')\n",
    "        plt.close(fig2)\n",
    "        \n",
    "    def init_model(self):\n",
    "        # Initialize model\n",
    "        rng = jax.random.PRNGKey(self.seed)\n",
    "        rng, init_rng = jax.random.split(rng)\n",
    "        params = self.model.init(init_rng, self.exmp)\n",
    "        # Initialize optimizer\n",
    "        optimizer = optax.adam(self.config['learning_rate'])\n",
    "        \n",
    "        # Initialize training state\n",
    "        self.state = train_state.TrainState.create(apply_fn=self.model.apply, params=params, tx=optimizer)\n",
    "        \n",
    "#     def init_linear_model(self):\n",
    "#         # Initialize model\n",
    "#         rng = jax.random.PRNGKey(self.seed)\n",
    "#         rng, init_rng = jax.random.split(rng)\n",
    "#         params = self.model.init(init_rng, jnp.ones((self.config['batch_size'], self.config['latent_size'])))\n",
    "#         return params\n",
    "        \n",
    "\n",
    "\n",
    "    def train_model(self, train_dataloader, test_dataloader, num_epochs=5):\n",
    "        # Train model for defined number of epochs\n",
    "        \n",
    "        self.state = jax_utils.replicate(self.state)\n",
    "        for epoch_idx in range(1, num_epochs+1):\n",
    "            self.train_epoch(epoch_idx, train_dataloader, test_dataloader)\n",
    "\n",
    "        self.state = jax_utils.unreplicate(self.state)\n",
    "        \n",
    "    def train_epoch(self, epoch, train_dataloader, test_dataloader):\n",
    "        train_dataiter = iter(train_dataloader)\n",
    "        test_dataiter = iter(test_dataloader)\n",
    "        \n",
    "        for batch in tqdm(range(len(train_dataloader)-1), desc=f'Epoch {epoch}'):\n",
    "            train_batch = common_utils.shard(jax.tree_util.tree_map(np.asarray, next(train_dataiter)))\n",
    "            test_batch = common_utils.shard(jax.tree_util.tree_map(np.asarray, next(test_dataiter)))\n",
    "            \n",
    "            self.state, train_loss = self.train_step(self.state, train_batch)\n",
    "            test_loss, recon_x = self.eval_step(self.state, test_batch)\n",
    "            \n",
    "            wandb.log({'train_loss': jax.device_get(train_loss.mean()), 'test_loss': jax.device_get(test_loss.mean())})\n",
    "            \n",
    "            # if self.state.step[0] % 100 == 0:\n",
    "            #     create_png(test_batch[0], recon_x)\n",
    "            #     wandb.log({'reconstruction' : [\n",
    "            #                 wandb.Image('recon.png')\n",
    "            #                 ], \n",
    "            #                'original image' : [\n",
    "            #                 wandb.Image('x.png')\n",
    "            #                 ]})\n",
    "            \n",
    "\n",
    "    def save_model(self, step=0):\n",
    "        # Save current model at certain training iteration\n",
    "        checkpoints.save_checkpoint(ckpt_dir=self.log_dir, target=self.state.params, prefix=f\"{index}_{config['latent_size']}\", step=self.state.step)\n",
    "\n",
    "    def load_model(self, pretrained=False):\n",
    "        # Load model. We use different checkpoint for pretrained models\n",
    "        if not pretrained:\n",
    "            params = checkpoints.restore_checkpoint(ckpt_dir=self.log_dir, target=self.state.params, prefix=f\"{config['projector_target']}_{config['latent_size']}\")\n",
    "        else:\n",
    "            params = checkpoints.restore_checkpoint(ckpt_dir=os.path.join(CHECKPOINT_PATH, f\"{config['projector_target']}_{config['latent_size']}.ckpt\"), target=self.state.params)\n",
    "        self.state = train_state.TrainState.create(apply_fn=self.model.apply, params=params, tx=self.state.tx)\n",
    "\n",
    "    def checkpoint_exists(self):\n",
    "        # Check whether a pretrained model exist for this autoencoder\n",
    "        return os.path.isfile(os.path.join(CHECKPOINT_PATH, f\"{config['projector_target']}_{config['latent_size']}.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61543f24-2895-4ce8-be81-140010cf40d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.dataloader.mel_dataset at 0x7faa854c4b20>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25cfb651-49e0-4367-80a2-2430fabec064",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_devices = jax.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41ba8fff-880a-4f85-94e2-e3101f6bb04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae420513-13f7-4b3e-908a-2b5f93baee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = jnp.ones((70000,48,1876))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d76a7f0-99fe-46c4-abe9-193002301a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "868dc62d-828a-4bcb-b7cf-a908d0996055",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ae8a092-8a10-442f-9644-b61f8025c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_complete_batches, leftover = divmod(num_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d29142f-b65c-465a-a09f-cfef0a36ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = num_complete_batches + bool(leftover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1c667b8-dff9-4092-8e3d-e6a04e6ee0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76add24a-7f74-4986-9fdf-9e764dfce904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_stream():\n",
    "    rng = jax.random.PRNGKey(303)\n",
    "    while True:\n",
    "        perm = rng.permutation(num_train)\n",
    "        for i in range(num_batches):\n",
    "            batch_idx = perm[i * batch_size(i+1) * batch_size]\n",
    "            x = x[batch_idx]\n",
    "            batch_size_per_device, ragged = divmoide(x.shape[0], num_devices)\n",
    "            if ragged:\n",
    "                msg = \"batch size must be divisible by device count, got {} and {}.\"\n",
    "                raise ValueError(msg.format(batch_size, num_devices))\n",
    "            shape_prefix = (num_devices, batch_size_per_device)\n",
    "            x = x.reshape(shape_prefix + x.shape[1:])\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58d5f9da-80f4-497c-8868-dda4e1c65574",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = data_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "889902c3-70a8-4805-afc0-43a085c30c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jit, grad, pmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0aee8d9b-6cd5-4b05-a023-7996ad682c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(pmap, axis_name='batch')\n",
    "def spmd_update(params, batch):\n",
    "    grads = grad(loss)(params, batch)\n",
    "    grads = [(jax.psum(dw, 'batch'), lax.psum(db, 'batch')) for dw, db in grads]\n",
    "    return [(w - step_size * dw, b - step_size * db)\n",
    "            for (w,b), (dw, db) in zip(params, grads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ebe8cf9-c5df-4ef8-87be-d86e5060704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random_params(scale, layer_sizes, rng=jax.random.PRNGKey(303)):\n",
    "    return [(scale * np.random.randn(m,n), scale * np.random.randn(n))\n",
    "            for m, n in zip(layer_sizes[:-1], layer_sizes[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89290d80-f7f6-485c-98a3-fcae1e8a134f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "870"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8aee6cc3-4dc2-44a1-a0a7-0063bb0810fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size = [870, 48, 1876]\n",
    "params_scale = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ae7bbb53-14bd-4156-a437-8adc798a1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = init_random_params(params_scale, layer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5726b6b9-6a0c-455d-9431-bc953019998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "replicate_array = lambda x:np.broadcast_to(x, (num_devices,) +x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "473d076e-2ee4-42b2-9d97-3f556bbe67e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.tree_util import tree_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "999f3983-7224-4fee-951f-482476576e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "replicated_params = tree_map(replicate_array, init_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "41ecff8b-b752-434c-ba13-dd0aef1b5099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1084316/572703657.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.array(replicated_params).shape\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (8,870,48) into shape (8,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [82]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicated_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (8,870,48) into shape (8,)"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_batches):\n",
    "        replicated_params = spmd_update(replicated_params, next(batches))\n",
    "    epoch_time = time.time - start_time\n",
    "    \n",
    "    params = tree_map("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ecbb6-2632-4f04-b7f2-199331e92322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
